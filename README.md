# python_NN_source_code_practice

## Description:
This is a source code practice to dig into the neural network model estimation process.
- based on a Matlab neural network fit module
- sample data from image pixels
- fit a neural network model for accurate image recognition

## 5.18 initial version coverage
- Forward Propogation on cost function estimation
- Built in two types of activation functions (tanh, sigmoid)
- Backpropogation on gradient derivation
- Tried different learning rate method (constant, decayed, scheduled, cycling, RMSProp)
- Tried batch gradient descent algorithm

## 7.11 coverage:
- Try Stochastic Gradient Descent Algorithms (SGD, mini-batch SGD)
- Try more adaptive learning rate methods (momentum, AdaGrad, Adam, others)

## Future investigations:
- Other activation functions categories
- Regression types of problems
